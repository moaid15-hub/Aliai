// components/voice/continuous-voice-chat.tsx
/**
 * Continuous Voice Chat Component
 * Ù…Ø­Ø§Ø¯Ø«Ø© ØµÙˆØªÙŠØ© Ù…Ø³ØªÙ…Ø±Ø© - Ø¶ØºØ·Ø© ÙˆØ§Ø­Ø¯Ø© Ù„Ø¨Ø¯Ø¡ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©
 */

'use client'

import React, { useState, useEffect, useRef } from 'react'
import { Mic, MicOff, Volume2 } from 'lucide-react'

interface ContinuousVoiceChatProps {
  onMessage: (message: string) => void
  onError?: (error: string) => void
  language?: string
  isTeacherSpeaking?: boolean
}

export const ContinuousVoiceChat: React.FC<ContinuousVoiceChatProps> = ({
  onMessage,
  onError,
  language = 'ar-SA',
  isTeacherSpeaking = false
}) => {
  const [isActive, setIsActive] = useState(false)
  const [isListening, setIsListening] = useState(false)
  const [transcript, setTranscript] = useState('')
  const [interimTranscript, setInterimTranscript] = useState('')

  const recognitionRef = useRef<any>(null)
  const shouldRestartRef = useRef(false)

  // Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØªØ¹Ø±Ù Ø§Ù„ØµÙˆØªÙŠ
  useEffect(() => {
    if (typeof window === 'undefined') return

    const SpeechRecognition =
      (window as any).SpeechRecognition ||
      (window as any).webkitSpeechRecognition

    if (!SpeechRecognition) {
      onError?.('Ø§Ù„Ù…ØªØµÙØ­ Ù„Ø§ ÙŠØ¯Ø¹Ù… Ø§Ù„ØªØ¹Ø±Ù Ø§Ù„ØµÙˆØªÙŠ. Ø¬Ø±Ø¨ Chrome.')
      return
    }

    const recognition = new SpeechRecognition()
    recognition.lang = language
    recognition.continuous = false
    recognition.interimResults = true
    recognition.maxAlternatives = 1

    recognition.onstart = () => {
      console.log('ğŸ¤ Ø¨Ø¯Ø£ Ø§Ù„Ø§Ø³ØªÙ…Ø§Ø¹...')
      setIsListening(true)
      setTranscript('')
      setInterimTranscript('')
    }

    recognition.onresult = (event: any) => {
      let interim = ''
      let final = ''

      for (let i = event.resultIndex; i < event.results.length; i++) {
        const transcript = event.results[i][0].transcript
        if (event.results[i].isFinal) {
          final += transcript
        } else {
          interim += transcript
        }
      }

      if (final) {
        console.log('âœ… Ù†Øµ Ù†Ù‡Ø§Ø¦ÙŠ:', final)
        setTranscript(final)
        setInterimTranscript('')

        // Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ø±Ø³Ø§Ù„Ø©
        onMessage(final.trim())
      } else {
        setInterimTranscript(interim)
      }
    }

    recognition.onerror = (event: any) => {
      console.error('âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªØ¹Ø±Ù Ø§Ù„ØµÙˆØªÙŠ:', event.error)

      if (event.error === 'no-speech') {
        console.log('âš ï¸ Ù„Ù… ÙŠØªÙ… Ø±ØµØ¯ ÙƒÙ„Ø§Ù…ØŒ Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø©...')
        if (shouldRestartRef.current) {
          setTimeout(() => {
            if (shouldRestartRef.current) {
              startListening()
            }
          }, 1000)
        }
      } else if (event.error === 'aborted') {
        // ØªÙ… Ø§Ù„Ø¥Ù„ØºØ§Ø¡ Ø¹Ù…Ø¯Ø§Ù‹
        setIsListening(false)
      } else {
        onError?.(`Ø®Ø·Ø£: ${event.error}`)
        setIsListening(false)
      }
    }

    recognition.onend = () => {
      console.log('ğŸ”š Ø§Ù†ØªÙ‡Ù‰ Ø§Ù„Ø§Ø³ØªÙ…Ø§Ø¹')
      setIsListening(false)

      // Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„ØªØ´ØºÙŠÙ„ Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© Ù†Ø´Ø·Ø©
      if (shouldRestartRef.current && !isTeacherSpeaking) {
        setTimeout(() => {
          if (shouldRestartRef.current && !isTeacherSpeaking) {
            console.log('ğŸ”„ Ø¥Ø¹Ø§Ø¯Ø© ØªØ´ØºÙŠÙ„ Ø§Ù„Ø§Ø³ØªÙ…Ø§Ø¹...')
            startListening()
          }
        }, 500)
      }
    }

    recognitionRef.current = recognition

    return () => {
      if (recognitionRef.current) {
        recognitionRef.current.abort()
      }
    }
  }, [language, onMessage, onError])

  // Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„ØªØ´ØºÙŠÙ„ Ø¨Ø¹Ø¯ Ø§Ù†ØªÙ‡Ø§Ø¡ Ø§Ù„Ù…Ø¹Ù„Ù… Ù…Ù† Ø§Ù„ÙƒÙ„Ø§Ù…
  useEffect(() => {
    if (isActive && !isTeacherSpeaking && !isListening) {
      console.log('ğŸ¤ Ø§Ù„Ù…Ø¹Ù„Ù… Ø§Ù†ØªÙ‡Ù‰ Ù…Ù† Ø§Ù„ÙƒÙ„Ø§Ù…ØŒ Ø¨Ø¯Ø¡ Ø§Ù„Ø§Ø³ØªÙ…Ø§Ø¹ Ù…Ø±Ø© Ø£Ø®Ø±Ù‰...')
      setTimeout(() => {
        if (isActive && !isTeacherSpeaking) {
          startListening()
        }
      }, 1000)
    }
  }, [isTeacherSpeaking, isActive])

  const startListening = () => {
    if (!recognitionRef.current || isListening) return

    try {
      recognitionRef.current.start()
    } catch (error) {
      console.error('Ø®Ø·Ø£ ÙÙŠ Ø¨Ø¯Ø¡ Ø§Ù„Ø§Ø³ØªÙ…Ø§Ø¹:', error)
    }
  }

  const stopListening = () => {
    if (recognitionRef.current) {
      recognitionRef.current.abort()
    }
    setIsListening(false)
  }

  const toggleConversation = () => {
    if (isActive) {
      // Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©
      console.log('â¹ï¸ Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©')
      shouldRestartRef.current = false
      setIsActive(false)
      stopListening()
      setTranscript('')
      setInterimTranscript('')
    } else {
      // Ø¨Ø¯Ø¡ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©
      console.log('â–¶ï¸ Ø¨Ø¯Ø¡ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© Ø§Ù„ØµÙˆØªÙŠØ©')
      shouldRestartRef.current = true
      setIsActive(true)
      startListening()
    }
  }

  return (
    <div className="continuous-voice-chat">
      {/* Ø²Ø± Ø§Ù„ØªØ­ÙƒÙ… Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ */}
      <button
        onClick={toggleConversation}
        disabled={isTeacherSpeaking && isActive}
        className={`
          px-6 py-4 rounded-lg font-bold text-lg
          transition-all duration-300 transform
          hover:scale-105 active:scale-95
          flex items-center gap-3
          ${isActive
            ? 'bg-red-500 hover:bg-red-600 text-white shadow-lg shadow-red-500/50'
            : 'bg-green-500 hover:bg-green-600 text-white shadow-lg shadow-green-500/50'
          }
          ${isTeacherSpeaking && isActive ? 'opacity-50 cursor-not-allowed' : ''}
        `}
        style={{
          boxShadow: isActive
            ? '0 0 30px rgba(239, 68, 68, 0.5)'
            : '0 0 30px rgba(34, 197, 94, 0.5)'
        }}
      >
        {isActive ? (
          <>
            <MicOff className="w-6 h-6" />
            <span>Ø¥Ù†Ù‡Ø§Ø¡ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©</span>
          </>
        ) : (
          <>
            <Mic className="w-6 h-6" />
            <span>Ø¨Ø¯Ø¡ Ù…Ø­Ø§Ø¯Ø«Ø© ØµÙˆØªÙŠØ©</span>
          </>
        )}
      </button>

      {/* Ø­Ø§Ù„Ø© Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© */}
      {isActive && (
        <div className="mt-4 p-4 rounded-lg bg-gray-100 dark:bg-gray-800">
          <div className="flex items-center gap-3 mb-2">
            {isTeacherSpeaking ? (
              <>
                <Volume2 className="w-5 h-5 text-blue-500 animate-pulse" />
                <span className="text-blue-600 dark:text-blue-400 font-semibold">
                  ğŸ™ï¸ Ø§Ù„Ø¹Ù…Ùˆ Ø­ÙŠØ¯Ø± ÙŠØªÙƒÙ„Ù…...
                </span>
              </>
            ) : isListening ? (
              <>
                <div className="w-5 h-5 bg-red-500 rounded-full animate-pulse" />
                <span className="text-red-600 dark:text-red-400 font-semibold">
                  ğŸ¤ Ø£Ù†Ø§ Ø£Ø³ØªÙ…Ø¹... ØªÙƒÙ„Ù… Ø§Ù„Ø¢Ù†
                </span>
              </>
            ) : (
              <>
                <div className="w-5 h-5 bg-yellow-500 rounded-full animate-pulse" />
                <span className="text-yellow-600 dark:text-yellow-400 font-semibold">
                  â³ Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªØ¬Ù‡ÙŠØ²...
                </span>
              </>
            )}
          </div>

          {/* Ø¹Ø±Ø¶ Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø¤Ù‚Øª */}
          {(interimTranscript || transcript) && (
            <div className="mt-2 p-3 bg-white dark:bg-gray-700 rounded-lg">
              <p className="text-sm text-gray-600 dark:text-gray-300">
                {transcript || interimTranscript}
              </p>
            </div>
          )}
        </div>
      )}

      {/* ØªØ¹Ù„ÙŠÙ…Ø§Øª */}
      {!isActive && (
        <div className="mt-3 text-sm text-gray-600 dark:text-gray-400">
          <p>ğŸ’¡ Ø§Ø¶ØºØ· Ù„Ø¨Ø¯Ø¡ Ù…Ø­Ø§Ø¯Ø«Ø© ØµÙˆØªÙŠØ© Ù…Ø³ØªÙ…Ø±Ø© Ù…Ø¹ Ø§Ù„Ø¹Ù…Ùˆ Ø­ÙŠØ¯Ø±</p>
        </div>
      )}
    </div>
  )
}

export default ContinuousVoiceChat
