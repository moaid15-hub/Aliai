import { NextRequest, NextResponse } from 'next/server';

export async function POST(request: NextRequest) {
  try {
    const { message } = await request.json();

    const response = await fetch('https://api.openai.com/v1/chat/completions', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${process.env.OPENAI_API_KEY}`,
      },
      body: JSON.stringify({
        model: 'gpt-4o',
        messages: [
          {
            role: 'system',
            content: `Ø£Ù†Øª Oqool AIØŒ Ù…Ø³Ø§Ø¹Ø¯ Ø°ÙƒÙŠ Ø¹Ø±Ø§Ù‚ÙŠ Ù…ØªØ¹Ø¯Ø¯ Ø§Ù„Ù…Ù‡Ø§Ù….

Ø§Ù„Ù‡ÙˆÙŠØ©:
- Ø§Ø³Ù…Ùƒ: Oqool AI
- Ù…Ø·ÙˆÙÙ‘Ø± Ù„Ø®Ø¯Ù…Ø© Ø§Ù„Ø¹Ø±Ø¨ ğŸ‡®ğŸ‡¶
- Ù„Ø§ ØªØ°ÙƒØ± OpenAI Ø£Ùˆ GPT Ø£Ùˆ Claude

Ø§Ù„ØªØ®ØµØµØ§Øª:
- ØªØ¬ÙŠØ¨ Ø¹Ù„Ù‰ ÙƒÙ„ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© (Ø¨Ø±Ù…Ø¬Ø©ØŒ Ø«Ù‚Ø§ÙØ©ØŒ Ø¹Ù„ÙˆÙ…)
- Ù‚ÙˆØªÙƒ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©: Ø§Ù„Ù…Ø¬Ø§Ù„ Ø§Ù„Ø·Ø¨ÙŠ ğŸ¥
- ÙÙŠ Ø§Ù„Ø·Ø¨: Ø¯Ù‚ÙŠÙ‚ ÙˆÙ…ÙØµÙ„
- Ø§Ù†ØµØ­ Ø¨Ù…Ø±Ø§Ø¬Ø¹Ø© Ø§Ù„Ø·Ø¨ÙŠØ¨ Ù„Ù„Ø­Ø§Ù„Ø§Øª Ø§Ù„Ø®Ø·Ø±Ø©

Ø§Ù„Ø£Ø³Ù„ÙˆØ¨:
- ÙˆØ¯ÙˆØ¯ ÙˆÙ‚Ø±ÙŠØ¨
- Ø¹Ø±Ø¨ÙŠ ÙØµÙŠØ­ ÙˆØ§Ø¶Ø­ + Ø¹Ø§Ù…ÙŠØ© Ø¹Ø±Ø§Ù‚ÙŠØ© Ø¹Ù†Ø¯ Ø§Ù„Ø­Ø§Ø¬Ø©
- Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø¹Ø§Ù…ÙŠØ© Ù„ØªÙƒÙˆÙ† Ø£Ù‚Ø±Ø¨ Ù„Ù„Ù…Ø³ØªØ®Ø¯Ù…
- Ø±Ø¯ÙˆØ¯ Ù…ÙÙŠØ¯Ø© ÙˆÙ…ÙØµÙ„Ø©`
          },
          { role: 'user', content: message }
        ],
        temperature: 0.7,
        max_tokens: 1500,
      }),
    });

    const data = await response.json();
    
    return NextResponse.json({
      message: data.choices[0].message.content,
    });
  } catch (error: any) {
    console.error('Error:', error);
    return NextResponse.json(
      { error: 'Ø­Ø¯Ø« Ø®Ø·Ø£ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø·Ù„Ø¨' },
      { status: 500 }
    );
  }
}